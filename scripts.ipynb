{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af86dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "ID_EMBED_DIM = 64                   # detail van kaarten \n",
    "LVL_EMBED_DIM = 8                   # detail van levels \n",
    "HIDDEN_DIMS = [512, 256]             # aantal neuronen in 1ste en 2de laag\n",
    "DROPOUT = 0.3                       # willekeurige neuronen \n",
    "BATCH_SIZE = 4096                  # aantal bekeken wedstrijden per keer \n",
    "EPOCHS = 10                        # aantal herhalingen van dataset\n",
    "LR = 0.001                          # diepgang van het model\n",
    "MODEL_DIR = \"pytorch_card_model\"    # getrainde model     \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # gebruik GPU(nvidia) indien mogelijk anders cpu \n",
    "print(\"Using device:\", device)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdca9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# 1. Zet hier al je bestandsnamen in een lijst\n",
    "bestanden_lijst = [\n",
    "    \"BattlesStaging_01012021_WL_tagged.csv\",\n",
    "    \"BattlesStaging_01022021_WL_tagged.csv\", \n",
    "    \"BattlesStaging_01032021_WL_tagged.csv\", \n",
    "    \"BattlesStaging_01042021_WL_tagged.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"BattlesStaging_01012021_WL_tagged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e63f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player1.card1.id</th>\n",
       "      <th>player1.card1.level</th>\n",
       "      <th>player1.card2.id</th>\n",
       "      <th>player1.card2.level</th>\n",
       "      <th>player1.card3.id</th>\n",
       "      <th>player1.card3.level</th>\n",
       "      <th>player1.card4.id</th>\n",
       "      <th>player1.card4.level</th>\n",
       "      <th>player1.card5.id</th>\n",
       "      <th>player1.card5.level</th>\n",
       "      <th>...</th>\n",
       "      <th>player2.card5.level</th>\n",
       "      <th>player2.card6.id</th>\n",
       "      <th>player2.card6.level</th>\n",
       "      <th>player2.card7.id</th>\n",
       "      <th>player2.card7.level</th>\n",
       "      <th>player2.card8.id</th>\n",
       "      <th>player2.card8.level</th>\n",
       "      <th>winner_player</th>\n",
       "      <th>winner.tag</th>\n",
       "      <th>loser.tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>player1</td>\n",
       "      <td>#PVLPJP2Y</td>\n",
       "      <td>#PLYJVUQY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>player1</td>\n",
       "      <td>#8PRLRYYCV</td>\n",
       "      <td>#92VG2CPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>player2</td>\n",
       "      <td>#2G8LQRCG</td>\n",
       "      <td>#2PCUY9U80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>player1</td>\n",
       "      <td>#Y9QL09VGV</td>\n",
       "      <td>#9GJJGYL8P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>player2</td>\n",
       "      <td>#9RRYG9P9U</td>\n",
       "      <td>#80J0LUCP8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player1.card1.id  player1.card1.level  player1.card2.id  \\\n",
       "0                 0                   13                 1   \n",
       "1                15                   13                16   \n",
       "2                23                   13                33   \n",
       "3                19                   11                36   \n",
       "4                42                   13                 5   \n",
       "\n",
       "   player1.card2.level  player1.card3.id  player1.card3.level  \\\n",
       "0                   13                 2                   13   \n",
       "1                   12                17                   12   \n",
       "2                   13                34                   13   \n",
       "3                    9                33                   11   \n",
       "4                   13                22                   13   \n",
       "\n",
       "   player1.card4.id  player1.card4.level  player1.card5.id  \\\n",
       "0                 3                   13                 4   \n",
       "1                18                   12                19   \n",
       "2                35                   13                 1   \n",
       "3                37                   10                21   \n",
       "4                16                   13                47   \n",
       "\n",
       "   player1.card5.level  ...  player2.card5.level  player2.card6.id  \\\n",
       "0                   13  ...                   13                12   \n",
       "1                   13  ...                   13                26   \n",
       "2                   13  ...                   13                31   \n",
       "3                   10  ...                   10                40   \n",
       "4                   13  ...                   13                45   \n",
       "\n",
       "   player2.card6.level  player2.card7.id  player2.card7.level  \\\n",
       "0                   13                13                   13   \n",
       "1                   13                12                   13   \n",
       "2                   13                14                   13   \n",
       "3                   10                26                   10   \n",
       "4                   13                18                   13   \n",
       "\n",
       "   player2.card8.id  player2.card8.level  winner_player  winner.tag  \\\n",
       "0                14                   13        player1   #PVLPJP2Y   \n",
       "1                27                   13        player1  #8PRLRYYCV   \n",
       "2                32                   13        player2   #2G8LQRCG   \n",
       "3                41                   10        player1  #Y9QL09VGV   \n",
       "4                46                   13        player2  #9RRYG9P9U   \n",
       "\n",
       "    loser.tag  \n",
       "0  #PLYJVUQY2  \n",
       "1   #92VG2CPY  \n",
       "2  #2PCUY9U80  \n",
       "3  #9GJJGYL8P  \n",
       "4  #80J0LUCP8  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Identify card ID and level columns\n",
    "# -------------------------------------------------------------------\n",
    "winner_id_cols   = [f\"winner.card{i}.id\" for i in range(1, 9)]                              # sla kaarten van winnaar op \n",
    "winner_lvl_cols  = [f\"winner.card{i}.level\" for i in range(1, 9)]                           # sla level op van kaarten winnaar \n",
    "loser_id_cols    = [f\"loser.card{i}.id\" for i in range(1, 9)]                               # sla kaarten van verliezer op\n",
    "loser_lvl_cols   = [f\"loser.card{i}.level\" for i in range(1, 9)]                            # sla kaartlevels van verliezer op \n",
    "\n",
    "all_card_id_cols = winner_id_cols + loser_id_cols                                           # sla alle gebruikte kaarten in de match op \n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Extract unique card IDs across all matches and remap to integers\n",
    "# -------------------------------------------------------------------\n",
    "unique_card_ids = pd.unique(df[all_card_id_cols].values.ravel())                            # geef elke kaart een unieke ID\n",
    "\n",
    "id_to_compact = {orig_id: idx for idx, orig_id in enumerate(unique_card_ids)}               \n",
    "\n",
    "# Save mapping\n",
    "with open(\"card_id_mapping.json\", \"w\") as f:                                                # hou vertaling van kaart -> unieke id bij \n",
    "    json.dump({str(k): v for k, v in id_to_compact.items()}, f)\n",
    "\n",
    "# Apply mapping\n",
    "for col in all_card_id_cols:                                                                # vervangt elke kaart door zijn unieke ID \n",
    "    df[col] = df[col].map(id_to_compact)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Subset dataset to only card id + card level + winner/loser tags\n",
    "# -------------------------------------------------------------------\n",
    "df_small = df[winner_id_cols + winner_lvl_cols + loser_id_cols + loser_lvl_cols + [\"winner.tag\", \"loser.tag\"]].copy()           #verwijderd nutteloze data\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Randomize who is player1 and player2\n",
    "# -------------------------------------------------------------------\n",
    "flip = np.random.randint(0, 2, size=len(df_small))  # 0 = swap, 1 = normal\n",
    "\n",
    "player1_ids   = np.where(flip[:, None] == 1, df_small[winner_id_cols].values,  df_small[loser_id_cols].values)      # winnaar staat eerst \n",
    "player1_lvls  = np.where(flip[:, None] == 1, df_small[winner_lvl_cols].values, df_small[loser_lvl_cols].values)\n",
    "\n",
    "player2_ids   = np.where(flip[:, None] == 1, df_small[loser_id_cols].values,  df_small[winner_id_cols].values)      # verliezer staat eerst \n",
    "player2_lvls  = np.where(flip[:, None] == 1, df_small[loser_lvl_cols].values, df_small[winner_lvl_cols].values)\n",
    "\n",
    "# Determine winner based on flip\n",
    "winner_player = np.where(flip == 1, \"player1\", \"player2\")                                                           # houdt bij welke speler eerst stond\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Build final cleaned DataFrame\n",
    "# -------------------------------------------------------------------\n",
    "final_data = {}\n",
    "\n",
    "# Player 1\n",
    "for i in range(1, 9):\n",
    "    final_data[f\"player1.card{i}.id\"]    = player1_ids[:, i-1]\n",
    "    final_data[f\"player1.card{i}.level\"] = player1_lvls[:, i-1]\n",
    "\n",
    "# Player 2\n",
    "for i in range(1, 9):\n",
    "    final_data[f\"player2.card{i}.id\"]    = player2_ids[:, i-1]\n",
    "    final_data[f\"player2.card{i}.level\"] = player2_lvls[:, i-1]\n",
    "\n",
    "# Winner label\n",
    "final_data[\"winner_player\"] = winner_player\n",
    "\n",
    "# Optional: keep original player tags\n",
    "final_data[\"winner.tag\"] = df_small[\"winner.tag\"].values\n",
    "final_data[\"loser.tag\"]  = df_small[\"loser.tag\"].values\n",
    "\n",
    "df_clean = pd.DataFrame(final_data)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Save final dataset\n",
    "# -------------------------------------------------------------------\n",
    "df_clean.to_csv(\"matches_clean_randomized.csv\", index=False)\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5ccae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows,cols: (2823527, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player1.card1.id</th>\n",
       "      <th>player1.card1.level</th>\n",
       "      <th>player1.card2.id</th>\n",
       "      <th>player1.card2.level</th>\n",
       "      <th>player1.card3.id</th>\n",
       "      <th>player1.card3.level</th>\n",
       "      <th>player1.card4.id</th>\n",
       "      <th>player1.card4.level</th>\n",
       "      <th>player1.card5.id</th>\n",
       "      <th>player1.card5.level</th>\n",
       "      <th>...</th>\n",
       "      <th>player2.card5.level</th>\n",
       "      <th>player2.card6.id</th>\n",
       "      <th>player2.card6.level</th>\n",
       "      <th>player2.card7.id</th>\n",
       "      <th>player2.card7.level</th>\n",
       "      <th>player2.card8.id</th>\n",
       "      <th>player2.card8.level</th>\n",
       "      <th>winner_player</th>\n",
       "      <th>winner.tag</th>\n",
       "      <th>loser.tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>player1</td>\n",
       "      <td>#PVLPJP2Y</td>\n",
       "      <td>#PLYJVUQY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>player1</td>\n",
       "      <td>#8PRLRYYCV</td>\n",
       "      <td>#92VG2CPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>player2</td>\n",
       "      <td>#2G8LQRCG</td>\n",
       "      <td>#2PCUY9U80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>player1</td>\n",
       "      <td>#Y9QL09VGV</td>\n",
       "      <td>#9GJJGYL8P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>player2</td>\n",
       "      <td>#9RRYG9P9U</td>\n",
       "      <td>#80J0LUCP8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player1.card1.id  player1.card1.level  player1.card2.id  \\\n",
       "0                 0                   13                 1   \n",
       "1                15                   13                16   \n",
       "2                23                   13                33   \n",
       "3                19                   11                36   \n",
       "4                42                   13                 5   \n",
       "\n",
       "   player1.card2.level  player1.card3.id  player1.card3.level  \\\n",
       "0                   13                 2                   13   \n",
       "1                   12                17                   12   \n",
       "2                   13                34                   13   \n",
       "3                    9                33                   11   \n",
       "4                   13                22                   13   \n",
       "\n",
       "   player1.card4.id  player1.card4.level  player1.card5.id  \\\n",
       "0                 3                   13                 4   \n",
       "1                18                   12                19   \n",
       "2                35                   13                 1   \n",
       "3                37                   10                21   \n",
       "4                16                   13                47   \n",
       "\n",
       "   player1.card5.level  ...  player2.card5.level  player2.card6.id  \\\n",
       "0                   13  ...                   13                12   \n",
       "1                   13  ...                   13                26   \n",
       "2                   13  ...                   13                31   \n",
       "3                   10  ...                   10                40   \n",
       "4                   13  ...                   13                45   \n",
       "\n",
       "   player2.card6.level  player2.card7.id  player2.card7.level  \\\n",
       "0                   13                13                   13   \n",
       "1                   13                12                   13   \n",
       "2                   13                14                   13   \n",
       "3                   10                26                   10   \n",
       "4                   13                18                   13   \n",
       "\n",
       "   player2.card8.id  player2.card8.level  winner_player  winner.tag  \\\n",
       "0                14                   13        player1   #PVLPJP2Y   \n",
       "1                27                   13        player1  #8PRLRYYCV   \n",
       "2                32                   13        player2   #2G8LQRCG   \n",
       "3                41                   10        player1  #Y9QL09VGV   \n",
       "4                46                   13        player2  #9RRYG9P9U   \n",
       "\n",
       "    loser.tag  \n",
       "0  #PLYJVUQY2  \n",
       "1   #92VG2CPY  \n",
       "2  #2PCUY9U80  \n",
       "3  #9GJJGYL8P  \n",
       "4  #80J0LUCP8  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 - Load CSV & inspect\n",
    "CSV_PATH = \"matches_clean_randomized.csv\"  # replace with your file path if different\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"rows,cols:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a42adeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N examples: 2823527\n",
      "Example ids p1: [0 1 2 3 4 5 6 7]\n",
      "Example lvls p1: [13 13 13 13 13 13 13 13]\n",
      "vocab_size (max id+1) = 102 max_level = 13\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Extract card id & level arrays and labels\n",
    "\n",
    "p1_id_cols = [f\"player1.card{i}.id\" for i in range(1,9)]                        # zoek naar kaartids van speler 1\n",
    "p1_lvl_cols = [f\"player1.card{i}.level\" for i in range(1,9)]                    # zoek naar levels van speler 1 \n",
    "p2_id_cols = [f\"player2.card{i}.id\" for i in range(1,9)]                        # zoek naar kaartids van speler 2 \n",
    "p2_lvl_cols = [f\"player2.card{i}.level\" for i in range(1,9)]                    # zoek naar levels van speler 2 \n",
    "\n",
    "# Safety check: ensure columns exist\n",
    "missing = [c for c in (p1_id_cols+p1_lvl_cols+p2_id_cols+p2_lvl_cols+[\"winner_player\"]) if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "# X arrays\n",
    "X_p1_ids  = df[p1_id_cols].fillna(-1).astype(int).values  # shape (N,8)  controle en verbetering van data \n",
    "X_p1_lvls = df[p1_lvl_cols].fillna(0).astype(int).values\n",
    "X_p2_ids  = df[p2_id_cols].fillna(-1).astype(int).values\n",
    "X_p2_lvls = df[p2_lvl_cols].fillna(0).astype(int).values\n",
    "\n",
    "# Label: 1 if player1 won else 0\n",
    "y = (df[\"winner_player\"] == \"player1\").astype(int).values           # waarde die het algoritme moet voorspellen\n",
    "\n",
    "print(\"N examples:\", len(y))                        \n",
    "print(\"Example ids p1:\", X_p1_ids[0])\n",
    "print(\"Example lvls p1:\", X_p1_lvls[0])\n",
    "\n",
    "# Determine vocab sizes\n",
    "max_card_id = int(np.max(np.concatenate([X_p1_ids.ravel(), X_p2_ids.ravel()])))             # zoekt hoogste kaartnummer\n",
    "if max_card_id < 0:     \n",
    "    raise ValueError(\"All card ids are negative or empty.\")                                 # error als er minder dan 0 kaarten zijn\n",
    "vocab_size = max_card_id + 1  # assuming ids start at 0                                     \n",
    "max_level = int(np.max(np.concatenate([X_p1_lvls.ravel(), X_p2_lvls.ravel()])))             # zoekt hoogste kaartlevel\n",
    "print(\"vocab_size (max id+1) =\", vocab_size, \"max_level =\", max_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae37fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val sizes: 2541174 282353\n",
      "class_weights: [1.0001913 0.9998088]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Train/Val split and class weights\n",
    "X = {                                           # alle variabelen verzameld in x \n",
    "    \"p1_ids\": X_p1_ids,\n",
    "    \"p1_lvls\": X_p1_lvls,\n",
    "    \"p2_ids\": X_p2_ids,\n",
    "    \"p2_lvls\": X_p2_lvls\n",
    "}\n",
    "\n",
    "Xw_train, Xw_val, Xl_train, Xl_val, y_train, y_val = train_test_split(                          # ongebruike code die de levels niet gebruikt\n",
    "    X[\"p1_ids\"], X[\"p2_ids\"], y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "# But we split p1 ids and p2 ids together via indexes; better create indices:\n",
    "# We'll create index split explicitly to keep lvls aligned\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)            # 0.1/1 is van de data is voor tests en de rest voor training \n",
    "train_idx, val_idx = next(sss.split(X[\"p1_ids\"], y))                                # maak lijst om te testen en een lijst om te trainen\n",
    "Xw_train_ids  = X[\"p1_ids\"][train_idx]                                              # maakt lijst met trainingdata\n",
    "Xw_train_lvls = X[\"p1_lvls\"][train_idx]\n",
    "Xl_train_ids  = X[\"p2_ids\"][train_idx]\n",
    "Xl_train_lvls = X[\"p2_lvls\"][train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "Xw_val_ids  = X[\"p1_ids\"][val_idx]                                                  # maakt lijst met testdata\n",
    "Xw_val_lvls = X[\"p1_lvls\"][val_idx]\n",
    "Xl_val_ids  = X[\"p2_ids\"][val_idx]\n",
    "Xl_val_lvls = X[\"p2_lvls\"][val_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(\"Train/Val sizes:\", len(y_train), len(y_val))\n",
    "\n",
    "# class weights for loss (optional)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)             # berekenen van reward system (moet ong gelijk zijn voor 1 en 2)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "print(\"class_weights:\", class_weights.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa581671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train: 621 val: 69\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Dataset and DataLoader\n",
    "class MatchDataset(Dataset):\n",
    "    def __init__(self, p1_ids, p1_lvls, p2_ids, p2_lvls, labels):               # kaarten ids en levels zijn gehele getallen en uitkomst is een kommagetal\n",
    "        self.p1_ids = torch.tensor(p1_ids, dtype=torch.long)\n",
    "        self.p1_lvls = torch.tensor(p1_lvls, dtype=torch.long)\n",
    "        self.p2_ids = torch.tensor(p2_ids, dtype=torch.long)\n",
    "        self.p2_lvls = torch.tensor(p2_lvls, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):                                                          # geeft aantal voorbeelden \n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):                                                 # geeft waardes van elke wedstrijd op basis van wedstrijdID\n",
    "        return (self.p1_ids[idx], self.p1_lvls[idx],\n",
    "                self.p2_ids[idx], self.p2_lvls[idx],\n",
    "                self.labels[idx])\n",
    "\n",
    "train_ds = MatchDataset(Xw_train_ids, Xw_train_lvls, Xl_train_ids, Xl_train_lvls, y_train)      # zet alle trainingdata samen \n",
    "val_ds   = MatchDataset(Xw_val_ids, Xw_val_lvls, Xl_val_ids, Xl_val_lvls, y_val)                # zet alle validatiedata samen\n",
    "\n",
    "# Zet workers op 0. Dit werkt ALTIJD, maar is ietsjes trager.\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    drop_last=False, \n",
    "    num_workers=0,         \n",
    "    pin_memory=True         # Dit mag wel aan blijven voor je GPU\n",
    "    # persistent_workers haal je weg, dat werkt niet met 0 workers\n",
    ")\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)                                 \n",
    "\n",
    "print(\"Batches train:\", len(train_loader), \"val:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e896a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerCardNet(\n",
      "  (id_embed): Embedding(102, 64)\n",
      "  (lvl_embed): Embedding(14, 8)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=72, out_features=72, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
      "        (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CounterAwareNet(nn.Module):\n",
    "    def __init__(self, vocab_size, max_level, id_emb_dim=64, lvl_emb_dim=8, hidden_dims=[512, 256], dropout=0.2, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Embeddings (Dezelfde als eerst)\n",
    "        self.id_embed = nn.Embedding(vocab_size, id_emb_dim)\n",
    "        self.lvl_embed = nn.Embedding(max_level + 1, lvl_emb_dim)\n",
    "        self.card_dim = id_emb_dim + lvl_emb_dim\n",
    "        \n",
    "        # 2. Transformer (Om de synergie BINNEN een deck te leren)\n",
    "        # We verwerken P1 en P2 nu APART, zodat we een zuivere representatie van elk deck krijgen\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.card_dim, nhead=num_heads, batch_first=True, dropout=dropout)\n",
    "        self.deck_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "        # 3. DE MAGISCHE INTERACTIE LAAG (Het Counter Mechanisme)\n",
    "        # We berekenen hoe elke kaart van P1 reageert op elke kaart van P2\n",
    "        # Dit resulteert in een 8x8 matrix per gevecht\n",
    "        \n",
    "        # 4. De Classifier (MLP)\n",
    "        # Input is: \n",
    "        # - Samenvatting P1 Deck (Global Average)\n",
    "        # - Samenvatting P2 Deck (Global Average)\n",
    "        # - De Counter Matrix (afgevlakt: 8*8 = 64 interacties)\n",
    "        \n",
    "        flattened_matrix_dim = 8 * 8 \n",
    "        input_dim = (self.card_dim * 2) + flattened_matrix_dim \n",
    "        \n",
    "        mlp_layers = []\n",
    "        inp = input_dim\n",
    "        for h in hidden_dims:\n",
    "            mlp_layers.append(nn.Linear(inp, h))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(dropout))\n",
    "            inp = h\n",
    "        mlp_layers.append(nn.Linear(inp, 1))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, p1_ids, p1_lvls, p2_ids, p2_lvls):\n",
    "        # A. Embeddings maken\n",
    "        p1_emb = torch.cat([self.id_embed(p1_ids), self.lvl_embed(p1_lvls)], dim=-1) # [Batch, 8, Dim]\n",
    "        p2_emb = torch.cat([self.id_embed(p2_ids), self.lvl_embed(p2_lvls)], dim=-1) # [Batch, 8, Dim]\n",
    "        \n",
    "        # B. Transformer: Leer de strategie van het deck zelf\n",
    "        p1_encoded = self.deck_encoder(p1_emb) # [Batch, 8, Dim]\n",
    "        p2_encoded = self.deck_encoder(p2_emb) # [Batch, 8, Dim]\n",
    "        \n",
    "        # C. INTERACTIE MATRIX (Dot Product Attention)\n",
    "        # Hier dwingen we het model om elke kaart met elke vijandelijke kaart te vergelijken\n",
    "        # matrix[i, j] vertelt ons hoe sterk Kaart i van P1 is tegen Kaart j van P2\n",
    "        # We gebruiken Batch Matrix Multiplication (bmm)\n",
    "        # [Batch, 8, Dim] x [Batch, Dim, 8] -> [Batch, 8, 8]\n",
    "        interaction_matrix = torch.bmm(p1_encoded, p2_encoded.transpose(1, 2))\n",
    "        \n",
    "        # Normaliseren helpt bij het leren (zodat waarden niet exploderen)\n",
    "        interaction_matrix = interaction_matrix / (self.card_dim ** 0.5)\n",
    "        interaction_features = interaction_matrix.flatten(start_dim=1) # [Batch, 64]\n",
    "        \n",
    "        # D. Samenvatting per deck (Global Average Pooling)\n",
    "        p1_summary = p1_encoded.mean(dim=1) # [Batch, Dim]\n",
    "        p2_summary = p2_encoded.mean(dim=1) # [Batch, Dim]\n",
    "        \n",
    "        # E. Alles samenvoegen en voorspellen\n",
    "        combined = torch.cat([p1_summary, p2_summary, interaction_features], dim=1)\n",
    "        logit = self.mlp(combined).squeeze(1)\n",
    "        \n",
    "        return logit\n",
    "\n",
    "# Model aanmaken met je krachtige GPU settings\n",
    "model = TransformerCardNet(\n",
    "    vocab_size=vocab_size, \n",
    "    max_level=max_level,\n",
    "    id_emb_dim=ID_EMBED_DIM,    # 64\n",
    "    lvl_emb_dim=LVL_EMBED_DIM,  # 8\n",
    "    hidden_dims=HIDDEN_DIMS,    # [512, 256]\n",
    "    dropout=DROPOUT,\n",
    "    num_heads=4                 # Aantal 'aandachts-punten' per kaart\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eb53ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Het model wordt opgeslagen als: pytorch_card_model\\ultimate_clash_model.pt\n",
      "Epoch 01  train_loss=0.6709  val_loss=0.6581  val_auc=0.6403  val_acc=0.5957\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 02  train_loss=0.6596  val_loss=0.6528  val_auc=0.6525  val_acc=0.6054\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 03  train_loss=0.6561  val_loss=0.6509  val_auc=0.6592  val_acc=0.6114\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 04  train_loss=0.6541  val_loss=0.6494  val_auc=0.6624  val_acc=0.6143\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 05  train_loss=0.6527  val_loss=0.6479  val_auc=0.6647  val_acc=0.6153\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 06  train_loss=0.6516  val_loss=0.6462  val_auc=0.6663  val_acc=0.6165\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 07  train_loss=0.6509  val_loss=0.6460  val_auc=0.6675  val_acc=0.6180\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 08  train_loss=0.6502  val_loss=0.6449  val_auc=0.6691  val_acc=0.6184\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 09  train_loss=0.6496  val_loss=0.6446  val_auc=0.6699  val_acc=0.6192\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n",
      "Epoch 10  train_loss=0.6490  val_loss=0.6442  val_auc=0.6704  val_acc=0.6192\n",
      "       ðŸ’¾ Opgeslagen op harde schijf.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# Use BCEWithLogitsLoss and pass pos_weight for imbalance (pos_weight = weight_for_positive_class)\n",
    "# compute pos_weight = class_weights[1] / class_weights[0] if using sklearn balanced weights\n",
    "# but easier: compute class counts\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "pos_weight = torch.tensor([neg / (pos + 1e-9)], dtype=torch.float32, device=device)  # >1 -> upweight positives\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "best_val_auc = 0.0  # We beginnen op 0\n",
    "naam_van_bestand = \"ultimate_clash_model.pt\" # Kies een goede naam\n",
    "save_path = os.path.join(MODEL_DIR, naam_van_bestand) \n",
    "\n",
    "print(f\"ðŸ’¾ Het model wordt opgeslagen als: {save_path}\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch in train_loader:\n",
    "        p1_ids_b, p1_lvls_b, p2_ids_b, p2_lvls_b, y_b = batch\n",
    "        p1_ids_b = p1_ids_b.to(device)\n",
    "        p1_lvls_b = p1_lvls_b.to(device)\n",
    "        p2_ids_b = p2_ids_b.to(device)\n",
    "        p2_lvls_b = p2_lvls_b.to(device)\n",
    "        y_b = y_b.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(p1_ids_b, p1_lvls_b, p2_ids_b, p2_lvls_b)\n",
    "        loss = criterion(logits, y_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_logits_all = []\n",
    "    val_y_all = []\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            p1_ids_b, p1_lvls_b, p2_ids_b, p2_lvls_b, y_b = batch\n",
    "            p1_ids_b = p1_ids_b.to(device)\n",
    "            p1_lvls_b = p1_lvls_b.to(device)\n",
    "            p2_ids_b = p2_ids_b.to(device)\n",
    "            p2_lvls_b = p2_lvls_b.to(device)\n",
    "            y_b = y_b.to(device)\n",
    "\n",
    "            logits = model(p1_ids_b, p1_lvls_b, p2_ids_b, p2_lvls_b)\n",
    "            loss = criterion(logits, y_b)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            val_logits_all.append(logits.cpu().numpy())\n",
    "            val_y_all.append(y_b.cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_logits_all = np.concatenate(val_logits_all)\n",
    "    val_y_all = np.concatenate(val_y_all)\n",
    "    val_probs = 1 / (1 + np.exp(-val_logits_all))  # sigmoid\n",
    "    val_auc = roc_auc_score(val_y_all, val_probs)\n",
    "    val_pred = (val_probs >= 0.5).astype(int)\n",
    "    val_acc = accuracy_score(val_y_all, val_pred)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}  train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  val_auc={val_auc:.4f}  val_acc={val_acc:.4f}\")\n",
    "\n",
    "# Save best model by AUC\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "# We maken een 'koffer' met alles wat we later nodig hebben\n",
    "        checkpoint_data = {\n",
    "            \"model_state\": model.state_dict(),  # De hersenen (gewichten)\n",
    "            \"vocab_size\": vocab_size,           # Instelling 1\n",
    "            \"max_level\": max_level,             # Instelling 2\n",
    "            \"id_emb_dim\": ID_EMBED_DIM,\n",
    "            \"lvl_emb_dim\": LVL_EMBED_DIM,\n",
    "            \"hidden_dims\": HIDDEN_DIMS,\n",
    "            \"dropout\": DROPOUT,\n",
    "            \"num_heads\": 4,                     # BELANGRIJK: Vergeet deze niet!\n",
    "            \"best_score\": best_val_auc          # Handig om te weten hoe goed hij was\n",
    "        }\n",
    "        \n",
    "        # Dit schrijft het daadwerkelijk naar je harde schijf\n",
    "        torch.save(checkpoint_data, save_path)\n",
    "        print(\"       ðŸ’¾ Opgeslagen op harde schijf.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   (Geen verbetering, we bewaren de oude versie met AUC {best_val_auc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bf5b477",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerCardNet:\n\tsize mismatch for id_embed.weight: copying a param with shape torch.Size([102, 32]) from checkpoint, the shape in current model is torch.Size([102, 64]).\n\tsize mismatch for transformer.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([120, 40]) from checkpoint, the shape in current model is torch.Size([216, 72]).\n\tsize mismatch for transformer.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for transformer.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([40, 40]) from checkpoint, the shape in current model is torch.Size([72, 72]).\n\tsize mismatch for transformer.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 40]) from checkpoint, the shape in current model is torch.Size([2048, 72]).\n\tsize mismatch for transformer.layers.0.linear2.weight: copying a param with shape torch.Size([40, 2048]) from checkpoint, the shape in current model is torch.Size([72, 2048]).\n\tsize mismatch for transformer.layers.0.linear2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm1.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm1.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([120, 40]) from checkpoint, the shape in current model is torch.Size([216, 72]).\n\tsize mismatch for transformer.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for transformer.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([40, 40]) from checkpoint, the shape in current model is torch.Size([72, 72]).\n\tsize mismatch for transformer.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 40]) from checkpoint, the shape in current model is torch.Size([2048, 72]).\n\tsize mismatch for transformer.layers.1.linear2.weight: copying a param with shape torch.Size([40, 2048]) from checkpoint, the shape in current model is torch.Size([72, 2048]).\n\tsize mismatch for transformer.layers.1.linear2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm1.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm1.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for mlp.0.weight: copying a param with shape torch.Size([512, 640]) from checkpoint, the shape in current model is torch.Size([512, 1152]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# instantiate a model with same hyperparams (from our variables)\u001b[39;00m\n\u001b[32m      5\u001b[39m loaded_model = TransformerCardNet(\n\u001b[32m      6\u001b[39m     vocab_size=ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m\"\u001b[39m, vocab_size),\n\u001b[32m      7\u001b[39m     max_level=ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mmax_level\u001b[39m\u001b[33m\"\u001b[39m, max_level),\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     num_heads=\u001b[32m4\u001b[39m  \u001b[38;5;66;03m# <--- Vergeet deze niet, die is nieuw!\u001b[39;00m\n\u001b[32m     13\u001b[39m ).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_state\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loaded_model.eval()\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_match\u001b[39m(p1_ids, p1_lvls, p2_ids, p2_lvls, model=loaded_model):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for TransformerCardNet:\n\tsize mismatch for id_embed.weight: copying a param with shape torch.Size([102, 32]) from checkpoint, the shape in current model is torch.Size([102, 64]).\n\tsize mismatch for transformer.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([120, 40]) from checkpoint, the shape in current model is torch.Size([216, 72]).\n\tsize mismatch for transformer.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for transformer.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([40, 40]) from checkpoint, the shape in current model is torch.Size([72, 72]).\n\tsize mismatch for transformer.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 40]) from checkpoint, the shape in current model is torch.Size([2048, 72]).\n\tsize mismatch for transformer.layers.0.linear2.weight: copying a param with shape torch.Size([40, 2048]) from checkpoint, the shape in current model is torch.Size([72, 2048]).\n\tsize mismatch for transformer.layers.0.linear2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm1.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm1.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.0.norm2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([120, 40]) from checkpoint, the shape in current model is torch.Size([216, 72]).\n\tsize mismatch for transformer.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for transformer.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([40, 40]) from checkpoint, the shape in current model is torch.Size([72, 72]).\n\tsize mismatch for transformer.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 40]) from checkpoint, the shape in current model is torch.Size([2048, 72]).\n\tsize mismatch for transformer.layers.1.linear2.weight: copying a param with shape torch.Size([40, 2048]) from checkpoint, the shape in current model is torch.Size([72, 2048]).\n\tsize mismatch for transformer.layers.1.linear2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm1.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm1.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for transformer.layers.1.norm2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for mlp.0.weight: copying a param with shape torch.Size([512, 640]) from checkpoint, the shape in current model is torch.Size([512, 1152])."
     ]
    }
   ],
   "source": [
    "# Cell 8 - Load model and prediction helper\n",
    "\n",
    "ckpt = torch.load(os.path.join(MODEL_DIR, \"best_model.pt\"), map_location=device)\n",
    "# instantiate a model with same hyperparams (from our variables)\n",
    "loaded_model = TransformerCardNet(\n",
    "    vocab_size=ckpt.get(\"vocab_size\", vocab_size),\n",
    "    max_level=ckpt.get(\"max_level\", max_level),\n",
    "    id_emb_dim=ID_EMBED_DIM,\n",
    "    lvl_emb_dim=LVL_EMBED_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    dropout=DROPOUT,\n",
    "    num_heads=4  # <--- Vergeet deze niet, die is nieuw!\n",
    ").to(device)\n",
    "loaded_model.load_state_dict(ckpt[\"model_state\"])\n",
    "loaded_model.eval()\n",
    "\n",
    "def predict_match(p1_ids, p1_lvls, p2_ids, p2_lvls, model=loaded_model):\n",
    "    \"\"\"\n",
    "    p?_ids and p?_lvls are sequences/lists/arrays length 8 each (ints).\n",
    "    Returns probability that player1 wins (float in [0,1]).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        p1_ids_t = torch.tensor([p1_ids], dtype=torch.long, device=device)\n",
    "        p1_lvls_t = torch.tensor([p1_lvls], dtype=torch.long, device=device)\n",
    "        p2_ids_t = torch.tensor([p2_ids], dtype=torch.long, device=device)\n",
    "        p2_lvls_t = torch.tensor([p2_lvls], dtype=torch.long, device=device)\n",
    "        logit = model(p1_ids_t, p1_lvls_t, p2_ids_t, p2_lvls_t)\n",
    "        prob = torch.sigmoid(logit).item()\n",
    "    return prob\n",
    "\n",
    "# quick test on a validation example\n",
    "example_idx = 0\n",
    "prob = predict_match(Xw_val_ids[example_idx], Xw_val_lvls[example_idx],\n",
    "                     Xl_val_ids[example_idx], Xl_val_lvls[example_idx])\n",
    "print(\"Pred prob player1 wins (example):\", prob, \"true label:\", int(y_val[example_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8f5b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Lezen van: ultimate_clash_model.pt\n",
      "âœï¸ Opslaan naar: ultimate_clash_model_v2.pt\n",
      "âœ… Model ingeladen. Huidige lat ligt op AUC: 0.6704\n",
      "ðŸš€ Start training voor nieuwe versie...\n",
      "Epoch +1: Train Loss=0.6468 | Val Loss=0.6425 | Val AUC=0.6732 | Acc=0.6214\n",
      "   --> ðŸŽ‰ Verbetering! (Was 0.6704, nu 0.6732)\n",
      "       Opgeslagen als 'ultimate_clash_model_v2.pt'\n",
      "Epoch +2: Train Loss=0.6462 | Val Loss=0.6425 | Val AUC=0.6735 | Acc=0.6217\n",
      "   --> ðŸŽ‰ Verbetering! (Was 0.6732, nu 0.6735)\n",
      "       Opgeslagen als 'ultimate_clash_model_v2.pt'\n",
      "Epoch +3: Train Loss=0.6459 | Val Loss=0.6424 | Val AUC=0.6737 | Acc=0.6222\n",
      "   --> ðŸŽ‰ Verbetering! (Was 0.6735, nu 0.6737)\n",
      "       Opgeslagen als 'ultimate_clash_model_v2.pt'\n",
      "Epoch +4: Train Loss=0.6456 | Val Loss=0.6423 | Val AUC=0.6741 | Acc=0.6225\n",
      "   --> ðŸŽ‰ Verbetering! (Was 0.6737, nu 0.6741)\n",
      "       Opgeslagen als 'ultimate_clash_model_v2.pt'\n",
      "Epoch +5: Train Loss=0.6454 | Val Loss=0.6422 | Val AUC=0.6742 | Acc=0.6223\n",
      "   --> ðŸŽ‰ Verbetering! (Was 0.6741, nu 0.6742)\n",
      "       Opgeslagen als 'ultimate_clash_model_v2.pt'\n",
      "ðŸ Klaar! Je origineel is veilig. De nieuwe versie (als hij beter was) heet: ultimate_clash_model_v2.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import os\n",
    "\n",
    "# --- 1. BESTANDSNAMEN INSTELLEN ---\n",
    "bestandsnaam_IN  = \"ultimate_clash_model.pt\"       # Het oude model (LEZEN)\n",
    "bestandsnaam_UIT = \"ultimate_clash_model_v2.pt\"    # Het nieuwe model (SCHRIJVEN)\n",
    "\n",
    "load_path = os.path.join(MODEL_DIR, bestandsnaam_IN)\n",
    "save_path = os.path.join(MODEL_DIR, bestandsnaam_UIT)\n",
    "\n",
    "EPOCHS_EXTRA = 5 \n",
    "FINE_TUNE_LR = 0.0001 # Ik heb dit iets veiliger gezet (van 0.0005 naar 0.0001)\n",
    "\n",
    "if 'train_loader' not in locals() or 'val_loader' not in locals():\n",
    "    print(\"âš ï¸ FOUT: Geen data gevonden. Draai eerst je data-inlaad cel!\")\n",
    "else:\n",
    "    if os.path.exists(load_path):\n",
    "        print(f\"ðŸ“– Lezen van: {bestandsnaam_IN}\")\n",
    "        print(f\"âœï¸ Opslaan naar: {bestandsnaam_UIT}\")\n",
    "        \n",
    "        # 1. LADEN\n",
    "        checkpoint = torch.load(load_path, map_location=device)\n",
    "        \n",
    "        # Instellingen ophalen\n",
    "        vocab = checkpoint.get(\"vocab_size\", vocab_size) \n",
    "        heads = checkpoint.get(\"num_heads\", 4)\n",
    "        hidden = checkpoint.get(\"hidden_dims\", HIDDEN_DIMS)\n",
    "        dropout = checkpoint.get(\"dropout\", DROPOUT)\n",
    "        emb_id = checkpoint.get(\"id_emb_dim\", ID_EMBED_DIM)\n",
    "        emb_lvl = checkpoint.get(\"lvl_emb_dim\", LVL_EMBED_DIM)\n",
    "        m_lvl = checkpoint.get(\"max_level\", max_level)\n",
    "        \n",
    "        # Beste score tot nu toe\n",
    "        best_val_auc = checkpoint.get(\"best_score\", 0.0)\n",
    "\n",
    "        # Model bouwen\n",
    "        model = TransformerCardNet(\n",
    "            vocab_size=vocab, max_level=m_lvl, id_emb_dim=emb_id,\n",
    "            lvl_emb_dim=emb_lvl, hidden_dims=hidden, dropout=dropout, num_heads=heads\n",
    "        ).to(device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        print(f\"âœ… Model ingeladen. Huidige lat ligt op AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "        # 2. TRAINING SETUP\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=FINE_TUNE_LR) \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        print(\"ðŸš€ Start training voor nieuwe versie...\")\n",
    "        \n",
    "        for epoch in range(1, EPOCHS_EXTRA + 1):\n",
    "            # --- FASE A: TRAINEN ---\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                p1_ids, p1_lvls, p2_ids, p2_lvls, y = batch\n",
    "                p1_ids, p1_lvls = p1_ids.to(device), p1_lvls.to(device)\n",
    "                p2_ids, p2_lvls = p2_ids.to(device), p2_lvls.to(device)\n",
    "                y = y.to(device).float()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = model(p1_ids, p1_lvls, p2_ids, p2_lvls)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "            \n",
    "            avg_train_loss = np.mean(train_losses)\n",
    "            \n",
    "            # --- FASE B: VALIDEREN ---\n",
    "            model.eval()\n",
    "            val_logits = []\n",
    "            val_targets = []\n",
    "            val_losses = [] # <--- DEZE WAS JE VERGETEN\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    p1_ids, p1_lvls, p2_ids, p2_lvls, y = batch\n",
    "                    p1_ids, p1_lvls = p1_ids.to(device), p1_lvls.to(device)\n",
    "                    p2_ids, p2_lvls = p2_ids.to(device), p2_lvls.to(device)\n",
    "                    y = y.to(device).float()\n",
    "                    \n",
    "                    logits = model(p1_ids, p1_lvls, p2_ids, p2_lvls)\n",
    "                    \n",
    "                    # Ook hier loss berekenen\n",
    "                    loss = criterion(logits, y) \n",
    "                    val_losses.append(loss.item())\n",
    "                    \n",
    "                    val_logits.append(logits.cpu().numpy())\n",
    "                    val_targets.append(y.cpu().numpy())\n",
    "            \n",
    "            # --- FASE C: METRICS BEREKENEN ---\n",
    "            # Alles samenvoegen\n",
    "            val_logits_concat = np.concatenate(val_logits)\n",
    "            val_y_concat = np.concatenate(val_targets)\n",
    "            \n",
    "            # Sigmoid voor kansen\n",
    "            val_probs = 1 / (1 + np.exp(-val_logits_concat))\n",
    "            \n",
    "            # Scores berekenen\n",
    "            current_auc = roc_auc_score(val_y_concat, val_probs)\n",
    "            val_pred = (val_probs >= 0.5).astype(int)\n",
    "            current_acc = accuracy_score(val_y_concat, val_pred)\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "            print(f\"Epoch +{epoch}: Train Loss={avg_train_loss:.4f} | Val Loss={avg_val_loss:.4f} | Val AUC={current_auc:.4f} | Acc={current_acc:.4f}\")\n",
    "\n",
    "            # --- FASE D: OPSLAAN (Onder de NIEUWE naam) ---\n",
    "            if current_auc > best_val_auc:\n",
    "                print(f\"   --> ðŸŽ‰ Verbetering! (Was {best_val_auc:.4f}, nu {current_auc:.4f})\")\n",
    "                print(f\"       Opgeslagen als '{bestandsnaam_UIT}'\")\n",
    "                best_val_auc = current_auc\n",
    "                \n",
    "                torch.save({\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"vocab_size\": vocab,\n",
    "                    \"num_heads\": heads,\n",
    "                    \"max_level\": m_lvl,\n",
    "                    \"hidden_dims\": hidden,\n",
    "                    \"id_emb_dim\": emb_id,\n",
    "                    \"lvl_emb_dim\": emb_lvl,\n",
    "                    \"dropout\": dropout,\n",
    "                    \"best_score\": best_val_auc\n",
    "                }, save_path) \n",
    "            else:\n",
    "                print(f\"   (Geen verbetering, we slaan niets op)\")\n",
    "\n",
    "        print(f\"ðŸ Klaar! Je origineel is veilig. De nieuwe versie (als hij beter was) heet: {bestandsnaam_UIT}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Kan bestand '{bestandsnaam_IN}' niet vinden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
